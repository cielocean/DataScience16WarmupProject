{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Iteration 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import re\n",
    "import operator\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import SelectKBest, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Importing Data as pandas dataframe\"\"\"\n",
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "#print(df_train.describe())\n",
    "#print(df_test.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Functions for formatting data\"\"\"\n",
    "\n",
    "#df_train = pd.read_csv(\"train.csv\")\n",
    "#df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "def format(df):\n",
    "    \"\"\" \n",
    "    formats all the data in the dataframe(df)\n",
    "    \"\"\"\n",
    "    format_age(df)    \n",
    "    format_fare(df)    \n",
    "    format_embarked(df)  \n",
    "    format_sex(df)    \n",
    "    format_familysize(df)\n",
    "    format_namelength(df)\n",
    "    return\n",
    "\n",
    "def format_wo_sex(df):\n",
    "    \"\"\" \n",
    "    formats all the data in the dataframe(df) except sex\n",
    "    \"\"\"\n",
    "    format_age(df)    \n",
    "    format_fare(df)    \n",
    "    format_embarked(df)   \n",
    "    format_familysize(df)\n",
    "    format_namelength(df)\n",
    "    return\n",
    "    \n",
    "def divide_all(df):\n",
    "    \"\"\"\n",
    "    divide formatted data and\n",
    "    returns new feature name as a list\n",
    "    \"\"\"\n",
    "    pclass_column = divide(df, 'Pclass')\n",
    "    age_column = divide(df, 'Age')\n",
    "    fare_column = divide(df, 'Fare')\n",
    "    embarked_column = divide(df, 'Embarked')\n",
    "    sex_column = divide(df, 'Sex')\n",
    "    familysize_column = divide(df, 'FamilySize')\n",
    "    return pclass_column + age_column + fare_column + embarked_column + sex_column + familysize_column\n",
    "\n",
    "def divide_all_wo_sex(df):\n",
    "    \"\"\"\n",
    "    divide formatted data and\n",
    "    returns new feature name as a list\n",
    "    \"\"\"\n",
    "    pclass_column = divide(df, 'Pclass')\n",
    "    age_column = divide(df, 'Age')\n",
    "    fare_column = divide(df, 'Fare')\n",
    "    embarked_column = divide(df, 'Embarked')\n",
    "    familysize_column = divide(df, 'FamilySize')\n",
    "    return pclass_column + age_column + fare_column + embarked_column + familysize_column\n",
    "\n",
    "\n",
    "def format_age(df):\n",
    "    \"\"\"\n",
    "    grouping age into agegroups (years old)\n",
    "    0: unknown age\n",
    "    1: infants (0-1) & toddlers (1-3)\n",
    "    2: preschoolers (3-5)\n",
    "    3: middle childhood (6-11)\n",
    "    4: young teen (12-14)\n",
    "    5: teenagers (15-17)\n",
    "    6: young adults (18-35)\n",
    "    7: middle-aged adults (36-55)\n",
    "    8: young older aduls (55-65)\n",
    "    9: retired (>65)\n",
    "    \n",
    "    \"\"\"\n",
    "    ag = {1:[0,3], 2:[3,5], 3:[5,11], 4:[11,14], 5:[14,17], 6:[17,35], 7:[35,55], 8:[55,65], 9:[65,150]}\n",
    "    df['Age'] = df['Age'].fillna(0)\n",
    "    \n",
    "    for i in range(1,10):\n",
    "        df.loc[(df['Age'] > ag[i][0]) & (df['Age'] <= ag[i][1]), 'Age'] = i\n",
    "    return\n",
    "\n",
    "def format_fare(df):\n",
    "    \"\"\"\n",
    "    grouping fare by amount the passenger paid\n",
    "    0: unknown\n",
    "    1: 0-10\n",
    "    2: 10-20\n",
    "    3: 20-30\n",
    "    4: 30-40\n",
    "    5: 40-550\n",
    "    \"\"\"\n",
    "    fg = {1:[0,10], 2:[10,20], 3:[20,30], 4:[30,40], 5:[40,550]}\n",
    "    df['Fare'] = df['Fare'].fillna(0)\n",
    "    \n",
    "    for i in range(1,6):\n",
    "        df.loc[(df['Fare'] > fg[i][0]) & (df['Fare'] <= fg[i][1]), 'Fare'] = i\n",
    "    return\n",
    "\n",
    "def format_embarked(df):\n",
    "    \"\"\"\n",
    "    change the value from string to float \n",
    "    for dividing up the columns later\n",
    "    0: no data available\n",
    "    1: Southampton\n",
    "    2: Cherbourg\n",
    "    3: Queenstown\n",
    "    \"\"\"\n",
    "    df['Embarked'] = df['Embarked'].fillna(0)\n",
    "    \n",
    "    df.loc[df[\"Embarked\"] == 'S', \"Embarked\"] =1\n",
    "    df.loc[df[\"Embarked\"] == 'C', \"Embarked\"] =2\n",
    "    df.loc[df[\"Embarked\"] == 'Q', \"Embarked\"] =3\n",
    "    return\n",
    "\n",
    "def format_sex(df):\n",
    "    \"\"\"\n",
    "    change the value from string to float \n",
    "    for dividing up the columns later\n",
    "    1: male\n",
    "    2: female\n",
    "    \"\"\"\n",
    "    df.loc[df['Sex'] == 'male', 'Sex'] = 1\n",
    "    df.loc[df['Sex'] == 'female', 'Sex'] = 2\n",
    "    return\n",
    "    \n",
    "def format_familysize(df):\n",
    "    \"\"\"\n",
    "    Generate column named FamilySize \n",
    "    which is the sum of number of family member onboard\n",
    "    \n",
    "    Group by familysize\n",
    "    0: unknown\n",
    "    1: 1\n",
    "    2: 2\n",
    "    3: 3-5\n",
    "    4: >5\n",
    "    5: 0\n",
    "    \"\"\"\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
    "    df['FamilySize'] = df['FamilySize'].fillna(0)\n",
    "    \n",
    "    df.loc[(df['FamilySize'] > 2) & (df['FamilySize'] <= 5), 'FamilySize'] = 3\n",
    "    df.loc[df['FamilySize'] > 5, 'FamilySize'] = 4\n",
    "    df.loc[df['FamilySize'] == 0, 'FamilySize'] = 5\n",
    "    return\n",
    "    \n",
    "def format_namelength(df):\n",
    "    \"\"\"\n",
    "    Generate column named NameLength\n",
    "    which shows the length of the name\n",
    "    \"\"\"\n",
    "    df[\"NameLength\"] = df[\"Name\"].apply(lambda x: len(x))\n",
    "    return\n",
    "\n",
    "def divide(df, column):\n",
    "    \"\"\"\n",
    "    Create new columns for column such that the values are 1 or 0\n",
    "    returns name of the newly generated columns(features) in a list\n",
    "    \n",
    "    example:\n",
    "    divide(df, 'Sex')\n",
    "    will result in columns Sex1 and Sex2, such that\n",
    "    Sex1 will have value 1 for all males and 0 for the rest & unknown\n",
    "    Sex2 will have value 1 for all females and 0 for the rest & unknown\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    for i in df[column].unique():\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            column_name = column + str(int(i))\n",
    "            df[column_name] = df[column]\n",
    "            columns.append(column_name)\n",
    "            df.loc[df[column_name] != i, column_name] = 0\n",
    "            df.loc[df[column_name] == i, column_name] = 1\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Formatting data\"\"\"\n",
    "format(df_train)\n",
    "format(df_test)\n",
    "train_columns = divide_all(df_train)\n",
    "test_columns = divide_all(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Checking to see if the columns of test data and train data are the same\"\"\"\n",
    "train_columns.sort()\n",
    "test_columns.sort()\n",
    "if train_columns == test_columns:\n",
    "    predictors = train_columns\n",
    "\n",
    "print train_columns == test_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out different types of regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.803591470258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:26: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Using Lineara Regression\"\"\"\n",
    "\n",
    "alg = LinearRegression()\n",
    "kf = KFold(df_train.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for train, test in kf:\n",
    "    # The predictors we're using the train the algorithm (only take the rows in the train folds)\n",
    "    train_predictors = (df_train[predictors].iloc[train,:])\n",
    "    # The target we're using to train the algorithm.\n",
    "    train_target = df_train[\"Survived\"].iloc[train]\n",
    "    # Training the algorithm using the predictors and target.\n",
    "    alg.fit(train_predictors, train_target)\n",
    "    # make predictions on the test fold\n",
    "    test_predictions = alg.predict(df_train[predictors].iloc[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# concatenate the predictions in three seperate numpy array on axis 0\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Map predictions to outcomes (only possible outcomes are 1 and 0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\n",
    "accuracy = sum(predictions[predictions == df_train[\"Survived\"]]) / len(predictions)\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nalg = LinearRegression()\\nalg.fit(df_train[predictors], df_train[\"Survived\"])\\nprediction = alg.predict(df_test[predictors].astype(float))[:,]\\npredictions.append(prediction)\\npredictions = np.concatenate(predictions, axis=0)\\npredictions[predictions > .5] = 1\\npredictions[predictions <=.5] = 0\\n'"
      ]
     },
     "execution_count": 601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "alg = LinearRegression()\n",
    "alg.fit(df_train[predictors], df_train[\"Survived\"])\n",
    "prediction = alg.predict(df_test[predictors].astype(float))[:,]\n",
    "predictions.append(prediction)\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "predictions[predictions > .5] = 1\n",
    "predictions[predictions <=.5] = 0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.799102132435\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Using LogisticRegression\"\"\"\n",
    "# Initialize our algorithm\n",
    "alg = LogisticRegression(random_state=1)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "scores = cross_validation.cross_val_score(alg, df_train[predictors], df_train[\"Survived\"], cv=3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.814814814815\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Using RandomForest\"\"\"\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2)\n",
    "# Compute the accuracy score for all the cross validation folds\n",
    "scores = cross_validation.cross_val_score(alg, df_train[predictors], df_train[\"Survived\"], cv=3)\n",
    "\n",
    "# Take the mean of the scores (because we have one for each fold)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtained submission score of 0.75120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAE2CAYAAACqSMMWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbWZWIw7aZmY14qBtZlYj/wfCVME/CPkFtAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd13b27a350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Finding the best features\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "predictors_original = ['Embarked', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'FamilySize', 'NameLength']\n",
    "predictors = predictors + predictors_original\n",
    "predictors.sort()\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(df_train[predictors], df_train[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "# Plot the scores for different features\n",
    "plt.bar(range(len(predictors)), scores)\n",
    "plt.xticks(range(len(predictors)), predictors, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812570145903\n"
     ]
    }
   ],
   "source": [
    "# Picking out the best features.\n",
    "predictors_filtered = ['Age1', 'Age2', 'Age4', 'Age9',\n",
    "              'Embarked1',\n",
    "              'FamilySize', \n",
    "              'Fare1', 'Fare2', \n",
    "              'NameLength',\n",
    "              'Pclass1', 'Pclass2',\n",
    "              'Sex']\n",
    "\n",
    "alg = RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=8, min_samples_leaf=4)\n",
    "scores = cross_validation.cross_val_score(alg, df_train[predictors_filtered], df_train[\"Survived\"], cv=3)\n",
    "\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Making predictions on test data\"\"\"\n",
    "# Train the algorithm using all the training data\n",
    "alg.fit(df_train[predictors], df_train[\"Survived\"])\n",
    "\n",
    "# Make predictions using the test set.\n",
    "predictions = alg.predict(df_test[predictors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.812570145903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:36: FutureWarning: in the future, boolean array-likes will be handled as a boolean array index\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Ensembling\"\"\"\n",
    "\n",
    "# The algorithms we want to ensemble.\n",
    "algorithms = [\n",
    "    #[GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors + predictors_original],\n",
    "    [RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2), predictors_filtered],\n",
    "    [LogisticRegression(random_state=1), predictors], #Use more linear predictors for the logistic regression\n",
    "]\n",
    "\n",
    "# Initialize the cross validation folds\n",
    "kf = KFold(df_train.shape[0], n_folds=3, random_state=1)\n",
    "\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_target = df_train[\"Survived\"].iloc[train]\n",
    "    full_test_predictions = []\n",
    "    # Make predictions for each algorithm on each fold\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm on the training data.\n",
    "        alg.fit(df_train[predictors].iloc[train,:], train_target)\n",
    "        # Select and predict on the test fold.  \n",
    "        # The .astype(float) is necessary to convert the dataframe to all floats and avoid an sklearn error.\n",
    "        test_predictions = alg.predict_proba(df_train[predictors].iloc[test,:].astype(float))[:,1]\n",
    "        full_test_predictions.append(test_predictions)\n",
    "    # Use a simple ensembling scheme -- just average the predictions to get the final classification.\n",
    "    test_predictions = (full_test_predictions[0] + full_test_predictions[1]) / 2\n",
    "    # Any value over .5 is assumed to be a 1 prediction, and below .5 is a 0 prediction.\n",
    "    test_predictions[test_predictions <= .5] = 0\n",
    "    test_predictions[test_predictions > .5] = 1\n",
    "    predictions.append(test_predictions)\n",
    "\n",
    "# Put all the predictions together into one array.\n",
    "predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# Compute accuracy by comparing to the training data.\n",
    "accuracy = sum(predictions[predictions == df_train[\"Survived\"]]) / len(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_predictions = []\n",
    "for alg, predictors in algorithms:\n",
    "    # Fit the algorithm using the full training data.\n",
    "    alg.fit(df_train[predictors], df_train[\"Survived\"])\n",
    "    # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "    predictions = alg.predict_proba(df_test[predictors].astype(float))[:,1]\n",
    "    full_predictions.append(predictions)\n",
    "\n",
    "# The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "predictions[predictions <= .5] = 0\n",
    "predictions[predictions > .5] = 1\n",
    "predictions = predictions.astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obtained submission score of 0.76555"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": df_test[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv('titanic_mi2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying machine learning separately on female and male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:71: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:103: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:134: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:135: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:147: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/jkim/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:167: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Age9'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-617-41f44620fbba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_predictors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_female_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_female_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0malg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_female_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Survived\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[0malg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_female_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredictors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_female_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Survived\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkim/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1962\u001b[0m             \u001b[1;31m# either boolean or fancy integer index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1964\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1965\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkim/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2005\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2006\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2007\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2008\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2009\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/jkim/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[1;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[0;32m   1148\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%s not in index'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Age9'] not in index\""
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "\"\"\"dividing male and female data\"\"\"\n",
    "df_male_train = df_train[df_train['Sex'] == 'male']\n",
    "df_female_train = df_train[df_train['Sex'] == 'female']\n",
    "\n",
    "df_male_test = df_test[df_test['Sex'] == 'male']\n",
    "df_female_test = df_test[df_test['Sex'] == 'female']\n",
    "\n",
    "def get_predictors(df_train, df_test):\n",
    "    \"\"\"format data and get predictiors as return value\"\"\"\n",
    "    \n",
    "    \"\"\"Formatting data\"\"\"\n",
    "    format(df_train)\n",
    "    format(df_test)\n",
    "    train_columns = divide_all(df_train)\n",
    "    test_columns = divide_all(df_test)\n",
    "\n",
    "    \"\"\"Checking to see if the columns of test data and train data are the same\"\"\"\n",
    "    train_columns.sort()\n",
    "    test_columns.sort()\n",
    "    #if train_columns == test_columns:\n",
    "    #    predictors = train_columns\n",
    "    #else:\n",
    "    #    predictors = test_columns\n",
    "\n",
    "    #print train_columns == test_columns\n",
    "    predictors = test_columns\n",
    "    return predictors\n",
    "\n",
    "def set_algorithm(predictors):\n",
    "    algorithms = [\n",
    "        #[GradientBoostingClassifier(random_state=1, n_estimators=25, max_depth=3), predictors + predictors_original],\n",
    "        [RandomForestClassifier(random_state=1, n_estimators=150, min_samples_split=4, min_samples_leaf=2), predictors],\n",
    "        [LogisticRegression(random_state=1), predictors], #Use more linear predictors for the logistic regression\n",
    "    ]\n",
    "    return algorithms\n",
    "\n",
    "\n",
    "def en_prediction(df_train, df_test, algorithms, predictors):\n",
    "    full_predictions = []\n",
    "    for alg, predictors in algorithms:\n",
    "        # Fit the algorithm using the full training data.\n",
    "        alg.fit(df_train[predictors], df_train[\"Survived\"])\n",
    "        # Predict using the test dataset.  We have to convert all the columns to floats to avoid an error.\n",
    "        predictions = alg.predict_proba(df_test[predictors].astype(float))[:,1]\n",
    "        full_predictions.append(predictions)\n",
    "\n",
    "    # The gradient boosting classifier generates better predictions, so we weight it higher.\n",
    "    predictions = (full_predictions[0] * 3 + full_predictions[1]) / 4\n",
    "    predictions[predictions <= .5] = 0\n",
    "    predictions[predictions > .5] = 1\n",
    "    predictions = predictions.astype(int)\n",
    "    return predictions\n",
    "\n",
    "def make_submission(df_test, predictions):\n",
    "    submission = pd.DataFrame({\n",
    "            \"PassengerId\": df_test[\"PassengerId\"],\n",
    "            \"Survived\": predictions\n",
    "        })\n",
    "    return submission\n",
    "\n",
    "predictors = get_predictors(df_male_train, df_male_test)\n",
    "algorithms = set_algorithm(predictors)\n",
    "predictions = en_prediction(df_male_train, df_male_test, algorithms, predictors)\n",
    "submission_male = make_submission(df_male_test, predictions)\n",
    "\n",
    "\"\"\"\n",
    "predictors = get_predictors(df_female_train, df_female_test)\n",
    "algorithms = set_algorithm(predictors)\n",
    "predictions = prediction(df_female_train, df_female_test, algorithms, predictors)\n",
    "submission_female = make_submission(df_female_test, predictions)\n",
    "\"\"\"\n",
    "predictors = get_predictors(df_female_train, df_female_test)\n",
    "alg = LogisticRegression()\n",
    "scores = cross_validation.cross_val_score(alg, df_female_train[predictors], df_train[\"Survived\"], cv=3)\n",
    "print(scores.mean())\n",
    "alg.fit(df_female_train[predictors], df_female_train[\"Survived\"])\n",
    "predictions = alg.predict(df_female_test[predictors])\n",
    "submission_female = make_submission(df_female_test, predictions)\n",
    "\n",
    "frames = [submission_male, submission_female]\n",
    "submission = pd.concat(frames)\n",
    "submission.to_csv('titanic_mi2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Source"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataquest\n",
    "https://www.dataquest.io/mission/74/getting-started-with-kaggle\n",
    "https://www.dataquest.io/mission/75/improving-your-submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
